% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kappas.R
\name{kappas}
\alias{kappas}
\title{Calcuate Cohens Kappa for OpenAI Model Outputs}
\usage{
kappas(df, groundtruth)
}
\arguments{
\item{df}{the dataframe created by this package's the results function}

\item{groundtruth}{The name of the column containing the ground_truth labels.}
}
\value{
a dataframe consisting of the Cohen's kappa between each model run and the ground truth
}
\description{
This function calculates Cohenâ€™s Kappa between a specified ground truth column
and each model's output column in a dataframe. It helps evaluate how closely
each model agrees with the human-labeled data, providing a standardized metric
of inter-annotator reliability.
}
\examples{
kappas(data, "groundtruth")
}
